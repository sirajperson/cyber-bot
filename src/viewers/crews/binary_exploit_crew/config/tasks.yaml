analyze_binary_challenge:
  description: >
    Analyze the provided CyberSkyline module data ('crawl_data') for a binary exploitation challenge.
    **Instructions:**
    1. Use the `FileTool` to determine the binary's file type.
    2. Use the `StringsTool` to extract printable strings from the binary. Analyze the strings for potential flags, passwords, or hints.
    3. Use the `BinwalkTool` to check for any embedded files or data within the binary.
    4. Based on the file type and findings from steps 1-3, determine the most appropriate advanced analysis tool (e.g., Ghidra for ELF/PE, dnSpy/.NET tools for .NET, GDB for dynamic analysis).
    5. Develop a clear, step-by-step plan describing how to use the chosen advanced tool to find the flag or vulnerability (e.g., "Load binary in Ghidra, navigate to function 'check_password', analyze decompiled code").
    6. If previous feedback ('feedback') is provided, incorporate it to correct the plan.
  expected_output: >
    A comprehensive analysis report including:
    - The output from `FileTool`.
    - Significant findings from `StringsTool`.
    - Findings from `BinwalkTool`.
    - The recommended advanced tool.
    - A clear, step-by-step plan for using the advanced tool.
    Example Plan Section:
    "Recommended Tool: Ghidra
    Plan:
    1. Load the binary into Ghidra using default analysis options.
    2. Locate the 'main' function in the Symbol Tree.
    3. Examine the decompiled code for the 'main' function.
    4. Follow function calls related to user input or validation logic.
    5. Identify potential buffer overflows or interesting comparisons."

validate_re_plan:
  description: >
    Review the proposed reverse engineering plan ('analysis_text').
    **Checklist:**
    1. Did the analyst correctly use and interpret `FileTool`, `StringsTool`, and `BinwalkTool`?
    2. Is the recommended advanced tool (Ghidra, GDB, dnSpy, etc.) appropriate for the file type identified by `FileTool` or implied by context?
    3. Are the steps described for the advanced tool logical, clear, and standard practice for the likely goal (finding flags, vulnerabilities)?
    4. Is the overall plan efficient, starting with basics before complex analysis?
  expected_output: >
    A JSON object adhering to the 'AnalysisVerification' Pydantic model, containing:
    - 'valid': boolean (True if the plan is sound, False otherwise).
    - 'feedback': string (Specific, actionable feedback if 'valid' is False, otherwise None or empty).
    Example valid: {"valid": true, "feedback": null}
    Example invalid: {"valid": false, "feedback": "Feedback: The plan correctly identified the file as ELF but jumped straight to recommending GDB for dynamic analysis. The `StringsTool` output clearly showed a hardcoded password which should be noted and tested first. Revise the plan to include checking the hardcoded string."}
